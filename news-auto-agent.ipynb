{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/estorl03-tech/AI-AGENT/blob/main/AI%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain_openai langchain_core tweepy requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoFSoh_3Etq5",
        "outputId": "cbde5b83-ae60-4981-de9b-8d811bc04ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.12/dist-packages (0.3.74)\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.12/dist-packages (4.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.100.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (25.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from tweepy) (3.3.1)\n",
            "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from tweepy) (2.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain_core) (0.24.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.2-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langchain_openai, langgraph-prebuilt, langgraph\n",
            "Successfully installed langchain_openai-0.3.30 langgraph-0.6.6 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.2 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 応用AIエージェント\n",
        "\n",
        "- ニュースを取得\n",
        "- 文書を要約\n",
        "- Tweetを投稿する\n"
      ],
      "metadata": {
        "id": "0JtBYUAst0TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from google.colab import userdata\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "import tweepy\n",
        "\n",
        "## APIキー\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "NEWS_API_KEY = userdata.get('NEWS_API_KEY')\n",
        "BEARER_TOKEN = userdata.get('BEARER_TOKEN')\n",
        "X_API_KEY = userdata.get('X_API_KEY')\n",
        "X_API_KEY_SECRET = userdata.get('X_API_KEY_SECRET')\n",
        "ACCESS_TOKEN = userdata.get('ACCESS_TOKEN')\n",
        "ACCESS_TOKEN_SECRET = userdata.get('ACCESS_TOKEN_SECRET')\n",
        "\n",
        "# 最新のニュースをひとつ取得するツール\n",
        "@tool\n",
        "def get_news(query: str) -> str:\n",
        "  \"\"\"キーワードに合致する最新ニュースを一件取得してタイトルと説明を返す\"\"\"\n",
        "  url = \"http://newsapi.org/v2/everything\"\n",
        "  params = {\n",
        "      \"q\": query,\n",
        "      \"sortBy\": \"publishedAt\",\n",
        "      \"pageSize\": 1,\n",
        "      \"apiKey\": NEWS_API_KEY\n",
        "  }\n",
        "\n",
        "  article = requests.get(url, params).json()[\"articles\"][0]\n",
        "  return f\"{article['title']} - {article['description']}\"\n",
        "\n",
        "# 140字以内で要約するツール\n",
        "@tool\n",
        "def summarize(text: str) -> str:\n",
        "  \"\"\"テキストを要約して返す\"\"\"\n",
        "  llm = ChatOpenAI(model = \"gpt-4o-mini-2024-07-18\", temperature = 0.1, openai_api_key = OPENAI_API_KEY)\n",
        "  return llm.invoke([SystemMessage(content=\"あなたは優秀な要約家です。以下のテキストを140字以内で簡潔に要約してください。）\"), HumanMessage(content = text)]).content\n",
        "\n",
        "# ツイートをするツール\n",
        "@tool\n",
        "def post_tweet(text: str) -> str:\n",
        "  \"\"\"テキストをツイートする\"\"\"\n",
        "  client = tweepy.Client(\n",
        "    bearer_token = BEARER_TOKEN,\n",
        "    consumer_key = X_API_KEY,\n",
        "    consumer_secret = X_API_KEY_SECRET,\n",
        "    access_token = ACCESS_TOKEN,\n",
        "    access_token_secret = ACCESS_TOKEN_SECRET\n",
        "  )\n",
        "\n",
        "  tweet = client.create_tweet(text = text)\n",
        "  return f\"{tweet.data['id']}\"\n",
        "\n",
        "# AIエージェント作成\n",
        "def run_agent(user_input: str) -> str:\n",
        "  tools = [get_news, summarize, post_tweet]\n",
        "\n",
        "  system_prompt = \"ユーザーの入力に対して、get_newsとsummarizeとpost_tweetから適切なツールを使って答えてください\"\n",
        "\n",
        "  llm = ChatOpenAI(model = \"gpt-4o-mini-2024-07-18\", temperature = 0, openai_api_key = OPENAI_API_KEY)\n",
        "  agent = create_react_agent(llm, tools, prompt=system_prompt)\n",
        "\n",
        "  response =  agent.invoke({\"messages\": [HumanMessage(content = user_input)]})\n",
        "  print(response[\"messages\"][-1].content)\n",
        "\n",
        "  return response\n",
        "\n",
        "# run_agentをそのまま使う\n",
        "def agent_interface(user_input):\n",
        "    try:\n",
        "        response = run_agent(user_input)\n",
        "        # LangGraphは messages を返すので、最後のAIMessage.contentを取り出す\n",
        "        messages = response[\"messages\"]\n",
        "        last_message = messages[-1]\n",
        "\n",
        "        # AIMessageの本文\n",
        "        if hasattr(last_message, \"content\"):\n",
        "          output_text = last_message.content\n",
        "        else:\n",
        "          output_text = str(last_message)\n",
        "\n",
        "        return f\"✅ 完了しました！\\n\\n{output_text}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"エラー: {e}\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ニュース取得 → 要約 → ツイート AIエージェント Demo\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            user_input = gr.Textbox(\n",
        "                label=\"入力（例: AI, 経済, スポーツ）\",\n",
        "                placeholder=\"気になるトピックを入力してください\"\n",
        "            )\n",
        "            run_button = gr.Button(\"実行\")\n",
        "\n",
        "        with gr.Column(scale=4):\n",
        "            output = gr.Textbox(\n",
        "                label=\"出力\",\n",
        "                lines=5\n",
        "            )\n",
        "\n",
        "    run_button.click(fn=agent_interface, inputs=user_input, outputs=output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "i9njX3_NYkqy",
        "outputId": "abbd9866-ecae-475d-acd7-fc919959a70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f3ccc8e7778a1a0937.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f3ccc8e7778a1a0937.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"人工知能に関するニュースを要約してツイートして\"\n",
        "response = run_agent(user_input)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjQHBQ5bYle_",
        "outputId": "df2e0113-abb3-453d-ec66-36c2fa37cf48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最新の人工知能に関するニュースをツイートしました。内容は以下の通りです：\n",
            "\n",
            "「米巨大テック企業、AI人材争奪戦で自らを脅かす」\n",
            "AI人材への需要が高まる中、企業は新しい技術の進展や倫理的課題、規制の動向に対応しなければならない。\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='人工知能に関するニュースを要約してツイートして', additional_kwargs={}, response_metadata={}, id='9f0e09b5-bded-443a-ae44-d5db883d3ed8'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0eIcE9En1f1fDn654kcOjr1A', 'function': {'arguments': '{\"query\": \"人工知能\"}', 'name': 'get_news'}, 'type': 'function'}, {'id': 'call_ug9Spw6nnR6vvad5h0kNhmjU', 'function': {'arguments': '{\"text\": \"人工知能に関する最新のニュース\"}', 'name': 'summarize'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 150, 'total_tokens': 205, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C6kfVWbjMA0CS5NBLVtYAF8ifRFkt', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--21354483-d60d-4884-9ec6-e31acd93e89f-0', tool_calls=[{'name': 'get_news', 'args': {'query': '人工知能'}, 'id': 'call_0eIcE9En1f1fDn654kcOjr1A', 'type': 'tool_call'}, {'name': 'summarize', 'args': {'text': '人工知能に関する最新のニュース'}, 'id': 'call_ug9Spw6nnR6vvad5h0kNhmjU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 150, 'output_tokens': 55, 'total_tokens': 205, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='米巨大テック企業、AI人材争奪戦で自らを蝕む - WSJ PickUp - 米国の巨大テック企業が抱く人工知能（AI）人材への飽くなき渇望は、金の卵を産むガチョウを自らの手で殺しかねない状況だ。', name='get_news', id='a6d9d680-85bd-4416-8cd6-7dd021edb9b3', tool_call_id='call_0eIcE9En1f1fDn654kcOjr1A'),\n",
              "  ToolMessage(content='人工知能に関する最新ニュースでは、技術の進展や新しいアプリケーション、倫理的課題、規制の動向などが取り上げられています。', name='summarize', id='d7464458-b2c1-4559-8197-9eeb916b3243', tool_call_id='call_ug9Spw6nnR6vvad5h0kNhmjU'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0VAVumrd15XYp06Dk1GNqUDa', 'function': {'arguments': '{\"text\":\"最新の人工知能ニュース: 「米巨大テック企業、AI人材争奪戦で自らを脅かす」\\\\nAI人材への需要が高まる中、企業は新しい技術の進展や倫理的課題、規制の動向に対応しなければならない。\"}', 'name': 'post_tweet'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 679, 'total_tokens': 765, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C6kfZwsAbFgif5B0ebeVJoz6ALxxk', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--77698077-a6c5-4235-95af-3d610155f447-0', tool_calls=[{'name': 'post_tweet', 'args': {'text': '最新の人工知能ニュース: 「米巨大テック企業、AI人材争奪戦で自らを脅かす」\\nAI人材への需要が高まる中、企業は新しい技術の進展や倫理的課題、規制の動向に対応しなければならない。'}, 'id': 'call_0VAVumrd15XYp06Dk1GNqUDa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 679, 'output_tokens': 86, 'total_tokens': 765, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='1958280391845982713', name='post_tweet', id='05de7640-67b1-4e18-8971-c0b635ae3d54', tool_call_id='call_0VAVumrd15XYp06Dk1GNqUDa'),\n",
              "  AIMessage(content='最新の人工知能に関するニュースをツイートしました。内容は以下の通りです：\\n\\n「米巨大テック企業、AI人材争奪戦で自らを脅かす」\\nAI人材への需要が高まる中、企業は新しい技術の進展や倫理的課題、規制の動向に対応しなければならない。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 781, 'total_tokens': 868, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C6kfcxJcUsayKlyJMpCQmgbNztznz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6b3a3d95-c15b-412d-893d-44bbcbd42932-0', usage_metadata={'input_tokens': 781, 'output_tokens': 87, 'total_tokens': 868, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJcV-XHvY3HB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
