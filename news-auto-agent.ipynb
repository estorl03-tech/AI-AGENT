{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/estorl03-tech/AI-AGENT/blob/main/news-auto-agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain_openai langchain_core tweepy requests"
      ],
      "metadata": {
        "id": "YoFSoh_3Etq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 応用AIエージェント\n",
        "\n",
        "- ニュースを取得\n",
        "- 文書を要約\n",
        "- Tweetを投稿する\n"
      ],
      "metadata": {
        "id": "0JtBYUAst0TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from google.colab import userdata\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "import tweepy\n",
        "\n",
        "## APIキー\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "NEWS_API_KEY = userdata.get('NEWS_API_KEY')\n",
        "BEARER_TOKEN = userdata.get('BEARER_TOKEN')\n",
        "X_API_KEY = userdata.get('X_API_KEY')\n",
        "X_API_KEY_SECRET = userdata.get('X_API_KEY_SECRET')\n",
        "ACCESS_TOKEN = userdata.get('ACCESS_TOKEN')\n",
        "ACCESS_TOKEN_SECRET = userdata.get('ACCESS_TOKEN_SECRET')\n",
        "\n",
        "# 最新のニュースをひとつ取得するツール\n",
        "@tool\n",
        "def get_news(query: str) -> str:\n",
        "  \"\"\"キーワードに合致する最新ニュースを一件取得してタイトルと説明を返す\"\"\"\n",
        "  url = \"http://newsapi.org/v2/everything\"\n",
        "  params = {\n",
        "      \"q\": query,\n",
        "      \"sortBy\": \"publishedAt\",\n",
        "      \"pageSize\": 1,\n",
        "      \"apiKey\": NEWS_API_KEY\n",
        "  }\n",
        "\n",
        "  article = requests.get(url, params).json()[\"articles\"][0]\n",
        "  return f\"{article['title']} - {article['description']}\"\n",
        "\n",
        "# 140字以内で要約するツール\n",
        "@tool\n",
        "def summarize(text: str) -> str:\n",
        "  \"\"\"テキストを要約して返す\"\"\"\n",
        "  llm = ChatOpenAI(model = \"gpt-4o-mini-2024-07-18\", temperature = 0, openai_api_key = OPENAI_API_KEY)\n",
        "  return llm.invoke([SystemMessage(content=\"以下のテキストを140字以内で簡潔に要約してください。）\"), HumanMessage(content = text)]).content\n",
        "\n",
        "# ツイートをするツール\n",
        "@tool\n",
        "def post_tweet(text: str) -> str:\n",
        "  \"\"\"テキストをツイートする\"\"\"\n",
        "  client = tweepy.Client(\n",
        "    bearer_token = BEARER_TOKEN,\n",
        "    consumer_key = X_API_KEY,\n",
        "    consumer_secret = X_API_KEY_SECRET,\n",
        "    access_token = ACCESS_TOKEN,\n",
        "    access_token_secret = ACCESS_TOKEN_SECRET\n",
        "  )\n",
        "\n",
        "  tweet = client.create_tweet(text = text)\n",
        "  return f\"{tweet.data['id']}\"\n",
        "\n",
        "# AIエージェント作成\n",
        "def run_agent(user_input: str) -> str:\n",
        "  tools = [get_news, summarize, post_tweet]\n",
        "\n",
        "  system_prompt = \"ユーザーの入力に対して、get_newsとsummarizeとpost_tweetから適切なツールを使って答えてください\"\n",
        "\n",
        "  llm = ChatOpenAI(model = \"gpt-4o-mini-2024-07-18\", temperature = 0, openai_api_key = OPENAI_API_KEY)\n",
        "  agent = create_react_agent(llm, tools, prompt=system_prompt)\n",
        "\n",
        "  response =  agent.invoke({\"messages\": [HumanMessage(content = user_input)]})\n",
        "  print(response[\"messages\"][-1].content)\n",
        "\n",
        "  return response\n",
        "\n",
        "# run_agentをそのまま使う\n",
        "def agent_interface(user_input):\n",
        "    try:\n",
        "        response = run_agent(user_input)\n",
        "        # LangGraphは messages を返すので、最後のAIMessage.contentを取り出す\n",
        "        messages = response[\"messages\"]\n",
        "        last_message = messages[-1]\n",
        "\n",
        "        # AIMessageの本文\n",
        "        if hasattr(last_message, \"content\"):\n",
        "          output_text = last_message.content\n",
        "        else:\n",
        "          output_text = str(last_message)\n",
        "\n",
        "        return f\"✅ 完了しました！\\n\\n{output_text}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"エラー: {e}\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ニュース取得 → 要約 → ツイート AIエージェント Demo\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            user_input = gr.Textbox(\n",
        "                label=\"入力（例: AI, 経済, スポーツ）\",\n",
        "                placeholder=\"気になるトピックを入力してください\"\n",
        "            )\n",
        "            run_button = gr.Button(\"実行\")\n",
        "\n",
        "        with gr.Column(scale=4):\n",
        "            output = gr.Textbox(\n",
        "                label=\"出力\",\n",
        "                lines=5\n",
        "            )\n",
        "\n",
        "    run_button.click(fn=agent_interface, inputs=user_input, outputs=output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "i9njX3_NYkqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"人工知能に関するニュースを要約してツイートして\"\n",
        "response = run_agent(user_input)"
      ],
      "metadata": {
        "id": "zjQHBQ5bYle_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJcV-XHvY3HB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}